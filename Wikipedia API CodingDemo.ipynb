{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPj4ZLJNLGC6IiVOYU3sNjM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"96tq_OIqYIxl"},"outputs":[],"source":["!pip install wikipedia\n","#Wikipedia API for Python uses a wrapper to easier extract content from user side. \n","import wikipedia"]},{"cell_type":"markdown","source":["Python has a Python API wrapper that performs the difficult parts for you. Serves as the middle man between you and the API. "],"metadata":{"id":"KGEDyCusjj1f"}},{"cell_type":"code","source":["#Set language\n","wikipedia.set_lang(\"en\")"],"metadata":{"id":"PZsqxQItibdj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Documentation\n","python package wikipedia. [documentation](https://wikipedia.readthedocs.io/en/latest/code.html#api).\n","\n","You can search for articles by keywords. Extract the page summary, content, html, links, etc. "],"metadata":{"id":"AX7f-8L-jxES"}},{"cell_type":"code","source":["#search wikipedia by search word. \n","#Creates list of article names. \n","covid = wikipedia.search(\"Covid\", results = 5)\n","print(covid)"],"metadata":{"id":"xzzZ0_zGiYqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Search list for specific article. No result\n","for i in covid:\n","    if(i == \"COVID-19 pandemic in Canada\"):\n","        print(covid.index(i))"],"metadata":{"id":"vxhzxETLiZ3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["covid = wikipedia.search(\"Covid\", results = 50)\n","print(covid)"],"metadata":{"id":"R3-iNRg2idQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Search list for specific article. \n","for i in covid:\n","    if(i == \"COVID-19 pandemic in Canada\"):\n","        print(covid.index(i))"],"metadata":{"id":"-fGtGvKyifk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Also could search directly for that. Pick the first result. Best match. \n","covid_can = wikipedia.search(\"COVID-19 pandemic in Canada\")[0]\n","print(covid_can)"],"metadata":{"id":"5Li6UAb4ihEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Use the wrapper to extract specific features. Documentation below.\n","#https://wikipedia.readthedocs.io/en/latest/code.html#api\n","#Load the specific page of following article title. \n","canada = wikipedia.page(\"COVID-19 pandemic in Canada\")"],"metadata":{"id":"w-IrxZAOijDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print top section. Summary\n","print(canada.summary)"],"metadata":{"id":"xYcpUprOikus"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Can print only 3 sentences of summary\n","print(wikipedia.summary(\"COVID-19 pandemic in Canada\", sentences=3))"],"metadata":{"id":"-OoNQokXimEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print the url link of article\n","print(canada.url)"],"metadata":{"id":"Ter1VVbOioCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print all the text of article.\n","print(canada.content)"],"metadata":{"id":"n6NgL4gmipvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print all the text for links in the document.\n","print(canada.links)"],"metadata":{"id":"PL0CJy2ciq43"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Can also print html and incorporate web scraping techniques to extract what I want.\n","html = canada.html()\n","print(html)"],"metadata":{"id":"1LSEMEjsir9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["See output from above line of code. We can then apply web scraping principles to extract specific sections of text."],"metadata":{"id":"eAg3xwEsldsY"}}]}